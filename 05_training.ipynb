{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9aa89636-40f8-440b-a375-40f5ee72f735",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-06 17:51:22.647323: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-07-06 17:51:22.656910: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:479] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-06 17:51:22.670645: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10575] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-06 17:51:22.670680: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1442] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-06 17:51:22.679718: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-06 17:51:23.199884: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow built with cuda? True\n",
      "TensorFlow built with GPU support? True\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import rasterio\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "import cv2\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import json\n",
    "import random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from skimage.transform import resize\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline\n",
    "        \n",
    "print(f'TensorFlow built with cuda? {tf.test.is_built_with_cuda()}')\n",
    "print(f'TensorFlow built with GPU support? {tf.test.is_built_with_gpu_support()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9eb3dbea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-06 17:51:24.723255: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:282] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "gpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc3dcdb-0f7e-4d7f-8e43-ea578c9f11d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = './images/overlap'\n",
    "\n",
    "images_dir ='./images/overlap/tiles'\n",
    "masks_dir = './images/overlap/masks'\n",
    "\n",
    "images_listdir = [img for img in os.listdir(images_dir) if img.endswith('jpg')]\n",
    "masks_listdir = [img for img in os.listdir(masks_dir) if img.endswith('jpg')]\n",
    "\n",
    "print(len(images_listdir))\n",
    "print(len(masks_listdir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5b009d-ffc5-4476-9503-152855ec517a",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_train, img_test = train_test_split(images_listdir, test_size=0.20)\n",
    "len(img_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d891a6a-6205-4d05-a3cc-a7a7b36793c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "masks_train, masks_test = train_test_split(masks_listdir, test_size=0.20)\n",
    "len(masks_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223ac13e-f8a1-4e28-9a3f-81d806aa1fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_train_path = os.path.join(images_dir, 'train')\n",
    "\n",
    "if not os.path.isdir(img_train_path):\n",
    "    os.makedirs(img_train_path)\n",
    "\n",
    "for img in img_train:\n",
    "    src = os.path.join(images_dir, img)\n",
    "    dst = os.path.join(img_train_path, img)\n",
    "    shutil.copyfile(src, dst)\n",
    "\n",
    "\n",
    "img_test_path = os.path.join(images_dir, 'test')\n",
    "\n",
    "if not os.path.isdir(img_test_path):\n",
    "    os.makedirs(img_test_path)\n",
    "\n",
    "for img in img_test:\n",
    "    src = os.path.join(images_dir, img)\n",
    "    dst = os.path.join(img_test_path, img)\n",
    "    shutil.copyfile(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd37399-9113-4a2c-8cbc-3201ee5ba12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "masks_train_path = os.path.join(masks_dir, 'train')\n",
    "\n",
    "if not os.path.isdir(masks_train_path):\n",
    "    os.makedirs(masks_train_path)\n",
    "\n",
    "for img in masks_train:\n",
    "    src = os.path.join(masks_dir, img)\n",
    "    dst = os.path.join(masks_train_path, img)\n",
    "    shutil.copyfile(src, dst)\n",
    "\n",
    "masks_test_path = os.path.join(masks_dir, 'test')\n",
    "\n",
    "if not os.path.isdir(masks_test_path):\n",
    "    os.makedirs(masks_test_path)\n",
    "\n",
    "for img in masks_test:\n",
    "    src = os.path.join(masks_dir, img)\n",
    "    dst = os.path.join(masks_test_path, img)\n",
    "    shutil.copyfile(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6261e62a-9fa9-4a60-837e-6b95571659b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_images = np.random.choice(images_listdir, size = 9, replace = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b6f328-19b3-47cf-84c0-68ebc1e4b919",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 1024\n",
    "input_image_size = (1024, 1024)\n",
    "\n",
    "def read_image(path):\n",
    "    img = cv2.imread(path)\n",
    "    img = cv2.resize(img, (image_size, image_size))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0522aa-b969-4e98-9f6a-0a21adb7d1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = 1\n",
    "cols = 3\n",
    "fig, ax = plt.subplots(rows, cols, figsize = (10,10))\n",
    "for i, ax in enumerate(ax.flat):\n",
    "    if i < len(random_images):\n",
    "        input_path = f\"{images_dir}/{random_images[i]}\"\n",
    "        img = read_image(input_path)\n",
    "        ax.set_title(f\"{random_images[i]}\")\n",
    "        ax.imshow(img)\n",
    "        ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e6cc23-ff43-4766-b28b-02ac75c39e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(rows, cols, figsize = (10,10))\n",
    "for i, ax in enumerate(ax.flat):\n",
    "    if i < len(random_images):\n",
    "        file=random_images[i]\n",
    "        if os.path.exists(os.path.join(masks_dir,file)):\n",
    "            img = read_image(f\"{masks_dir}/{file}\")\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            ax.set_title(f\"{random_images[i]}\")\n",
    "            ax.imshow(img)\n",
    "            ax.axis('off')\n",
    "        else:\n",
    "            print('not exist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4869e815-7026-4a9e-bc36-a20c4e87ee5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "masks_listdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46b38cc-0c25-4008-a537-f693e3a9daec",
   "metadata": {},
   "outputs": [],
   "source": [
    "MASKS = np.zeros((1,image_size, image_size, 1), dtype=bool)\n",
    "IMAGES = np.zeros((1,image_size, image_size, 3), dtype=np.uint8)\n",
    "\n",
    "\n",
    "for j, file in enumerate(img_train):   ##the smaller, the faster\n",
    "    image = read_image(f\"{img_train_path}/{file}\")\n",
    "    image_ex = np.expand_dims(image, axis=0)\n",
    "    IMAGES = np.vstack([IMAGES, image_ex])\n",
    "    file2 = file[0:-4]+'.jpg'\n",
    "    mask = read_image(f\"{masks_dir}/{file2}\")\n",
    "    mask = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)\n",
    "    mask = mask.reshape(1024, 1024, 1)\n",
    "    mask_ex = np.expand_dims(mask, axis=0)\n",
    "    MASKS = np.vstack([MASKS, mask_ex])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439a3a59-4da8-4976-8ea4-7d9fe8080d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "TMASKS = np.zeros((1,image_size, image_size,1), dtype=bool)\n",
    "TIMAGES = np.zeros((1,image_size, image_size,3),dtype=np.uint8)\n",
    "\n",
    "for j, file in enumerate(img_test):\n",
    "    image = read_image(f\"{img_test_path}/{file}\")\n",
    "    image_ex = np.expand_dims(image, axis=0)\n",
    "    TIMAGES = np.vstack([TIMAGES, image_ex])\n",
    "    file2 = file[0:-4]+'.jpg'\n",
    "    mask = read_image(f\"{masks_dir}/{file2}\")\n",
    "    mask = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)\n",
    "    mask = mask.reshape(1024, 1024, 1)\n",
    "    mask_ex = np.expand_dims(mask, axis=0)\n",
    "    TMASKS = np.vstack([TMASKS, mask_ex])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fcc057-c3c3-4349-93a0-dcea28181806",
   "metadata": {},
   "outputs": [],
   "source": [
    "images=np.array(IMAGES)\n",
    "masks=np.array(MASKS)\n",
    "print('Train')\n",
    "print(images.shape, masks.shape)\n",
    "\n",
    "test_images=np.array(TIMAGES)\n",
    "test_masks=np.array(TMASKS)\n",
    "\n",
    "print('Test')\n",
    "print(test_images.shape, test_masks.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2644acb2-af8c-42ed-8464-068a32c2d5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_train, images_test, masks_train, masks_test = train_test_split(\n",
    "    images, masks, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b570611b-c6f8-424b-b95d-60fabe40f285",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(images_train), len(masks_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c86278-41f8-45de-838d-16a4d59678a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def iou_coeff(y_true, y_pred):\n",
    "    # Calcula la intersección entre el y_true y y_pred\n",
    "    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n",
    "    # Calcula la unión\n",
    "    union = K.sum(y_true, -1) + K.sum(y_pred, -1) - intersection\n",
    "    # Calcula el coeficiente de IoU\n",
    "    iou = (intersection + K.epsilon()) / (union + K.epsilon())\n",
    "    return iou\n",
    "\n",
    "def conv_block(input, num_filters):\n",
    "    conv = tf.keras.layers.Conv2D(num_filters, 3, padding=\"same\")(input)\n",
    "    conv = tf.keras.layers.BatchNormalization()(conv)\n",
    "    conv = tf.keras.layers.Activation(\"relu\")(conv)\n",
    "    conv = tf.keras.layers.Conv2D(num_filters, 3, padding=\"same\")(conv)\n",
    "    conv = tf.keras.layers.BatchNormalization()(conv)\n",
    "    conv = tf.keras.layers.Activation(\"relu\")(conv)\n",
    "    return conv\n",
    "\n",
    "def encoder_block(input, num_filters):\n",
    "    skip = conv_block(input, num_filters)\n",
    "    pool = tf.keras.layers.MaxPool2D((2,2))(skip)\n",
    "    return skip, pool\n",
    "\n",
    "def decoder_block(input, skip, num_filters):\n",
    "    up_conv = tf.keras.layers.Conv2DTranspose(num_filters, (2,2), strides=2, padding=\"same\")(input)\n",
    "    conv = tf.keras.layers.Concatenate()([up_conv, skip])\n",
    "    conv = conv_block(conv, num_filters)\n",
    "    return conv\n",
    "\n",
    "def Unet(input_shape):\n",
    "    inputs = tf.keras.layers.Input(input_shape)\n",
    "\n",
    "    skip1, pool1 = encoder_block(inputs, 64)\n",
    "    skip2, pool2 = encoder_block(pool1, 128)\n",
    "    skip3, pool3 = encoder_block(pool2, 256)\n",
    "    skip4, pool4 = encoder_block(pool3, 512)\n",
    "\n",
    "    bridge = conv_block(pool4, 1024)\n",
    "\n",
    "    decode1 = decoder_block(bridge, skip4, 512)\n",
    "    decode2 = decoder_block(decode1, skip3, 256)\n",
    "    decode3 = decoder_block(decode2, skip2, 128)\n",
    "    decode4 = decoder_block(decode3, skip1, 64)\n",
    "    outputs = tf.keras.layers.Conv2D(1, 1, padding=\"same\", activation=\"sigmoid\")(decode4)\n",
    "    model = tf.keras.models.Model(inputs, outputs, name=\"U-Net\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836e1c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0663f6f-4051-46a8-89aa-c227b44a3fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "unet_model = Unet((1024, 1024, 3))\n",
    "unet_model.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "unet_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e70cba4-fc32-45ad-8bbf-e8452a68f04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "unet_result = unet_model.fit(\n",
    "    images_train, masks_train,\n",
    "    validation_split = 0.2, batch_size = 4, epochs =3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fe5cba-93e8-4353-946b-ef2925cadbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "unet_model.save('./modelos/unet_1024_3epochs_cpu.kerasNVIDIA GeForce GTX 1650 with Max-Q Design')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87fce52-8f02-4627-a243-4ba486f39b5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
